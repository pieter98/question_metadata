{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QM01_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EA_zrAZrgZsG",
        "zkuC_BOeyDja"
      ],
      "authorship_tag": "ABX9TyMq6WcBIlpp0Wj52uHgP8Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pieter98/question_metadata/blob/main/QM_notebooks/QM01_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing of the data\n",
        "This notebook is purely focused on the preprocessing of the data.\n",
        "\n",
        "We will transform the existing data to a format that is usuable for the other notebooks.\n",
        "\n",
        "\n",
        "\n",
        "#### **!! for GDPR reasons the data used in this notebook is limited to only a few anonymised data samples ¡¡**"
      ],
      "metadata": {
        "id": "IHa8pA4BaKeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The data\n",
        "\n",
        "The availlable data is a full export of questions from the *assessmentQ* platform developped by *Televic Education* ([assessmentQ website](https://assessmentq.com/)). \n",
        "\n",
        "AssessmentQ is a digital assessment and interactive practice platform which allows it's teachers/lectors to create exams, distribute access to the exams to students, partake in exams, gather useful metrics and reports based on the exam results,... . \n",
        "\n",
        "The data was gathered over the past data and consists of exam/test questions created by the users of the platform."
      ],
      "metadata": {
        "id": "dKCPLwDSaZ1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format of the data\n",
        "\n",
        "the most relevant fields in the data structure (JSON):\n",
        "\n",
        "```\n",
        "{\n",
        "  \"Id\": \"...\", // question id\n",
        "  \"Type\": \"...\", // FGQ: Fill Gaps Question, MCQ: Multiple Choice Question, OQ: Open Question\n",
        "  \"Name\": \"...\", // question name\n",
        "  \"Instruction\": \"...\", // question instruction (in HTML format)\n",
        "  ...\n",
        "  \"Answers\": [...], // question answers if present (OQ does not have a default answer)\n",
        "  ...\n",
        "  \"Metadata\": { // extra metadata (Added by tools or users)\n",
        "    \"Language\": \"...\", // question language\n",
        "    \"Subject\": \"...\", // question subject (mostly null values or incorrect labelling)\n",
        "    \"Sector\": \"...\", // sector of the client, this field is determined by the creators company\n",
        "    ...\n",
        "    \"Custom\": [...], // custom metadata added by users\n",
        "    \"Location\": \"...\" // location of the question within the assessmentQ filestructure\n",
        "  }\n",
        "}\n",
        "```\n",
        "Full data examples can be found [here](https://github.com/pieter98/question_metadata/tree/main/data)."
      ],
      "metadata": {
        "id": "BfpGE6anc651"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. extracting relevant text fields\n",
        "\n",
        "First and foremost we must determine which fields of the data are useable for determining the qustion topic. To accomplish this we mainly look at the following fields: \n",
        "\n",
        "- Name: the question name can contain useful info about the question (e.g. \"Math question 1\")\n",
        "- Instruction: this property contains the instruction text of the question (in HTML) -> the main explanation of the question.\n",
        "- Answers: the answers can provide us with useful insights into the topic (also in HTML format)\n",
        "- Metadata > Location: The Location metadata contains a textual representation of the folder location within assessmentQ where the question is located (see image).\n",
        "![image-1.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFBpZXRlciBQYW5nYXQAAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzk1AACSkgACAAAAAzk1AADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIyOjA1OjE4IDEyOjQ1OjE1ADIwMjI6MDU6MTggMTI6NDU6MTUAAABQAGkAZQB0AGUAcgAgAFAAYQBuAGcAYQB0AAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjItMDUtMThUMTI6NDU6MTUuOTUyPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPlBpZXRlciBQYW5nYXQ8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgAygInAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+j8yf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUZk/ur/wB9f/Wp1FADcyf3V/76/wDrUZk/ur/31/8AWp1FADcyf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUZk/ur/wB9f/Wp1FADcyf3V/76/wDrUZk/ur/31/8AWp1FADcyf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUZk/ur/wB9f/Wp1FADcyf3V/76/wDrUZk/ur/31/8AWp1FADcyf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUZk/ur/wB9f/Wp1FADcyf3V/76/wDrUZk/ur/31/8AWp1FADcyf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUZk/ur/wB9f/Wp1FADcyf3V/76/wDrUZk/ur/31/8AWp1FADcyf3V/76/+tRmT+6v/AH1/9anUUANzJ/dX/vr/AOtRmT+6v/fX/wBanUUANzJ/dX/vr/61GZP7q/8AfX/1qdRQA3Mn91f++v8A61GZP7q/99f/AFqdRQA3Mn91f++v/rUU6igAooooAKKKKACiiigAorN12a4h08fZZvJdnClwuSBg9PyrnFudUVgf7TkODnBUGvPxGOjQnyOLf3f5kuVjtaKxE8QsEAe3BbHJD4BP0xViy1kXd0sJgKbgcHdntn0raOMoSaSer9R3Rp0UVnajrlrpk0kdysh8qzlvJHUDCpHjOeepzx9DXUPc0aKxNV8SjTbuwtYtKv7+5vo5JY4bbygUVNu7cZJFH8Y6E0+y8QDU7OSTT7G4a4guVt7m0m2xyQEldxbJwcKwbgnI6Zp2Dpc2KKKgF5bm/ayEgNysQlMeDkISQD+YP5UgJ6KKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDhdf1LX/BWtXGr+Xd69oN4R5lrCoaeylwAvljjMbHAI7E59c6vhG18QuLnVvFNyUuL7aY9MjIMVkgzhc9S/PzH/AV0tFC0QPUy9f/AOPBP+uo/ka5+un1W1ku7MJDgsrhsE4zwf8AGsX+x77/AJ4/+Pj/ABrw8bSqSrXjFsiSdylV3R/+QrD/AMC/9BNH9j33/PH/AMfH+NW9M0y5gvklmUIqZ/iBzkEdqwo0Kqqxbi910Ek7m5XkWvaDJf69q8jeEfDcjy3FraF2ny3mO+9nz9nzuZZF3HqAP4q9dqH7Fa+YX+zQ72kEpbyxkuBtDZ9cADPXAxX0fW5p0aOKv9NvLTxN4XtNDj0zRJks70mGO2M9vHkwlgqqYs8nOeO/FO17RTpOhpLcXJu72+12wnuZygQM3nxKAqj7qhVAAyfcmu1e2ge5juHhjaeJWWOUoCyBsbgD1AOBn1wKJ7aC6RUuYY5lV1kVZEDAMpyrc9wQCD2Ipp2afn+twe1jzS80/Udd1bxKPsOky39vctHa3t5qLxT2CeWpjaNRC2wfxZDDcc56VsWujafN8UpLjUbCwmvl0i2mE5gUnzRJIC6kjOeFGeuNvtXUX+g6Rqs8c2qaVZXssX+rkuLdJGT6FgcVLc6XYXtxbz3ljbXE1q26CSWFWaE+qkjKn6Uo6W8v8rf8EHrfz/zT/wCAea6Vp2ratbnUY7PR4tWTUmMuqS6k4uots/MJTyeF2jYI9+MEHvXR+HtJsr3xZ4kvr2Bbie11UC3Mo3CA/ZoSWQHhWOeSOeBXRTaDo9zqSajcaVYy30eNl09sjSrjphyMircVtBA8rwQxxtM/mSsiAGRsAbmx1OABk9gKcdPu/wAv8hNX/r1/zJKKKKQwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8Ajgo8uX/nt/44KlooAi8uX/nt/wCOCjy5f+e3/jgqWigCLy5f+e3/AI4KPLl/57f+OCpaKAIvLl/57f8AjgoqWigAooooAKKKKACiiigAooooAKKK4zUonm1K4Zrq4H7xgAHwAAeAK5MViXh4pqN7ibsdnRXIaddXGml/KmeVW6rMdwB9RV7+37r/AJ5w/wDfJ/xrCGYU5RvJWYuZHQ0VBY3DXVlHM6hWYHIHscU+4njtbaWedgkUSF3Y9FAGSa9BSTjzLYpa7ElFYvhrxF/wkGhtfPZvZTRuyy2sj7mjOAy5OO6Mre26s7/hLr6603w9NpelQTXGtxGRYri8MSQgR7z84jYn0+6Kpq39dwOrorF0zXp59VbStYsBp+oeUZ41SbzopowQCUfCk4JGQVB5HWmW/ieK48ZXGhC3YLDFlbrd8rygKzx4x1CyIevOT6UAbtFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBl+ItCi8R6JLp81xcWpYh457eQo8Tqcqwx1wQDg8VxUel+NvE8q+H/FBSx0uyYC8v7STa+rDqqqB/qwR9/wB+BivSaKFoweoiKERVXOFGBkkn8zXJXv8Ax/3H/XVv5111Yl1oc0t1JJHLHtdi3zZBGTXn46lOpFcquTJdjGorU/sC5/56Rfmf8KP7Auf+ekX5n/CvJ+q1/wCUizNPR/8AkFQ/8C/9CNY/jXzr7T7fQbKRI7jV5vJLvGXVIlG+QsoIyCo29R98c1vWdv8AZbRId27bnnHqc1PX0NKLjTin0SNVojjLOLU9D8XyLrF7aXKa1bEI1raG3VZoV6EGR8loyec9I6xtO1Kx0nRvh5d6peQWduto4aa4kCICbfgZPFemUVr0t6fr/mBxNzrVnqPiaHxBZSGXSND0+5ee9QHy5WfYQiN0fAjJJGQCQOtZj6R4i0nw/a69eX1k/wBiuTq1xbJYuJvnyZk83zSDhHYD5Odo6V6TRQtNv61v/XoG+j/r+tfvGxyLLGskbBkcBlYHgg96dRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQA3yx6t/30aPLHq3/AH0adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/AH0aPLHq3/fRp1FADfLHq3/fRo8serf99GnUUAN8serf99Gjyx6t/wB9GnUUAN8serf99Gjyx6t/30adRQA3yx6t/wB9Gjyx6t/30adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/fRo8serf8AfRp1FADfLHq3/fRo8serf99GnUUAN8serf8AfRo8serf99GnUUAN8serf99Gjyx6t/30adRQA3yx6t/30aPLHq3/AH0adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/AH0aPLHq3/fRp1FADfLHq3/fRo8serf99GnUUAN8serf99Gjyx6t/wB9GnUUAN8serf99Gjyx6t/30adRQA3yx6t/wB9Gjyx6t/30adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/fRo8serf8AfRp1FADfLHq3/fRo8serf99GnUUAN8serf8AfRo8serf99GnUUAN8serf99Gjyx6t/30adRQA3yx6t/30aPLHq3/AH0adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/AH0aPLHq3/fRp1FADfLHq3/fRo8serf99GnUUAN8serf99Gjyx6t/wB9GnUUAN8serf99Gjyx6t/30adRQA3yx6t/wB9Gjyx6t/30adRQA3yx6t/30aPLHq3/fRp1FADfLHq3/fRo8serf8AfRp1FADfLHq3/fRo8serf99GnUUAN8serf8AfRop1FABRRRQAUUUUAFFFFABRRRQAUUUUAFNkkWKMu5wBTqz9cs5L/SJ7eBijujKGXqMqVyPcZz+FAC2et2F/M0VtcRyOp2kK6tg+hwTg/Wr9eM/Cz4Xav4Q8RXd5f3kUkUkfkokG7DAOrb2yBjocDrzXq82mySzM4u5EDHO0dv1oAv0VRt9PeC4WRrqSQLn5T0PH1q9QAUVxek+JdQj8a6lY6tKsmnT3rWthJsC+TKkauYmI67gxIJ5yrD0q/YeI/s2l6pe6vK8i2+py2sKxxgu3zhY41AHJJIH8zQtbeav+X+Yf52/P/I6WiuePjG1him+32N7ZXFu8ImtpljLokr7EkyrlSmc5IYkYPFW08SWL+JbnQ/3guba3Fw7lR5ZHGQDn7wDKSMdGFAGtRWXFq8GoeFf7XjFxDbzWhuF4AlVCuQQMkZxyKxh4qubfUtD0+x0nUNRt77Tzc+eXhEhA8vBO6RRkb8tx1IxnnDs72/rr/kH9fl/mdbRXP3fjCztLi5BtLyWzs5PKu7+NF8m3bjIbLBjjIyVVgO5GDS33i2G11K8sLbTNR1C4skSWdbWNCFRgSGyzqD0PA+b0Bqb6XDrY36K52y8aWV/NYGGzvlstRO20v5IlWGVipIXG7eMgHBKgHHB5FdFVWAKKKKQBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFQ3UrRxqI8BnbaCe3Gc/pU1RzQrNHtYkc5BHUH1oAq+ZLAyt5rOu4Bg2O5xxRNq1vBM0biTcpwcAf41Klo29TNLvCnIULjn3qxsU9VH5UAVLfVILmdYow+5s4yPbNXKQIoOQoB+lLQBy0fhl76z8Q2moq0C3uom4tZkYFkISPZKuOhDJkZ9Kx4vDGuah4Nki1a3SLU01Y3xigumiWfawyVkjOU3DJHcEjNeg0Uf8AA/C3+SDf8fxv/mcVbeGYdQ03V420fVdOuLuzNqJtS1M3bkckbczSbQGOeo5rNuvDPiK58LRXiW6xeILy4mN6gkT93HMnlEbs4OxVibg87OK9Hoo/r+vXqH9fp+BQvrH/AIpy4sLJOfsjQxJnH8BAHP4Vz6abqmm3Hhm9j06S7+xac1lcwQyxh42YRfN8zBSAYyDg55GAa6+imnZt9/8Ag/5sVtEu3/A/yPPJvCLQXWpWl5o2raraX91LMHtNakhh2SncyyRGZAMEkfKrZHJ54rpdP0y5tvEmuXLQ7be6it0gbcDu2IwI65GMjrW9RUtXjyj3lzHHWehalF4S8I2Ulti406a3a6Tev7sLGwbnODgkdM12NFFU3dt93f8Ar7gCiiikAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50ebH/fX86AHUU3zY/wC+v50ebH/fX86AHUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50ebH/fX86AHUU3zY/wC+v50ebH/fX86AHUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50ebH/fX86AHUU3zY/wC+v50ebH/fX86AHUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50ebH/fX86AHUU3zY/wC+v50ebH/fX86AHUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50ebH/fX86AHUU3zY/wC+v50ebH/fX86AHUU3zY/76/nR5sf99fzoAdRTfNj/AL6/nR5sf99fzoAdRTfNj/vr+dHmx/31/OgB1FN82P8Avr+dHmx/31/OgB1FN82P++v50UAHlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/Kjyo/7i/lTqKAG+VH/AHF/Kjyo/wC4v5U6igBvlR/3F/KinUUAf//Z)\n",
        "Alot of users use the folder system to indicate the topics of their questions, therefor this data could be very useful (but it depends highly on the user and the user's company).\n",
        "\n",
        "\n",
        "We'll extract the textual data from all of these fields and add them as new properties to the data JSON. \n",
        "\n",
        "\n",
        "**Disclaimer: the preprocessing code is by no means efficient, it is a quick and dirty way to achieve what we needed**\n"
      ],
      "metadata": {
        "id": "EA_zrAZrgZsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. installing and importing necessary libraries"
      ],
      "metadata": {
        "id": "zkuC_BOeyDja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BeautifulSoup for HTML parsing\n",
        "!pip install beautifulsoup4\n",
        "# tqdm for visualising processing progress\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNELPfSS0WVk",
        "outputId": "e2673425-d90f-48c0-81e6-70aa7058958e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "RgZxSDOC2Ryw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Data before text extraction\n",
        "In this part we define a helper method to print out the json data. A quick print of a datapoint before preprocessing is shown."
      ],
      "metadata": {
        "id": "Azd-QOx658ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_json_helper(filename):\n",
        "  file = open(filename, \"r\")\n",
        "  file_json = json.load(file)\n",
        "  pretty_json = json.dumps(file_json, indent=4)\n",
        "  print(pretty_json)\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "To6_bVL05cwd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to quickly check if the datafolder is present we can use the \"!ls\" command. The data should be added in the \"data\" folder."
      ],
      "metadata": {
        "id": "kyjnIecr6Kks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2yR7M-j56F0",
        "outputId": "485b710c-cb6a-44dd-d3c2-4a845751194c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick test print of a single data file before any preprocessing has been applied"
      ],
      "metadata": {
        "id": "x9UyVKd06VN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_json_helper(\"data/sample.mcq.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1DriN3P6XrL",
        "outputId": "edb9b85b-fdfa-442f-9cf4-0973c44e115c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Id\": \"0000FBB0-D511-4151-A468-06F215620C31\",\n",
            "    \"Type\": \"MCQ\",\n",
            "    \"Name\": null,\n",
            "    \"Instruction\": \"<p style=\\\"text-align:justify;font-size:15px;\\\">Which of these rivers is the longest?</p>\",\n",
            "    \"Answers\": [\n",
            "        {\n",
            "            \"Value\": \"<p>Amazon River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 0\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Danube River</p>\",\n",
            "            \"IsCorrect\": true,\n",
            "            \"ChoiceId\": 1\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Nile River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 2\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Hudson River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 3\n",
            "        }\n",
            "    ],\n",
            "    \"Scoring\": {\n",
            "        \"MaxScore\": 10.0,\n",
            "        \"MinScore\": 0.0\n",
            "    },\n",
            "    \"Metadata\": {\n",
            "        \"Language\": \"eng\",\n",
            "        \"Subject\": null,\n",
            "        \"Sector\": \"Secondary Education\",\n",
            "        \"Difficulty\": null,\n",
            "        \"CustomerId\": null,\n",
            "        \"Custom\": [],\n",
            "        \"Location\": \"Content 2021 > ENG > Geography\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Textual data extraction method\n",
        "The following method is a slightly edited version of the one that can be found [here](https://github.com/pieter98/question_metadata/blob/main/pre_processing_methods/language_extractor.py). The method takes the data directory path as input and iterates over all files within this directory"
      ],
      "metadata": {
        "id": "hOb2RNQM42a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "===================================================================================================================\n",
        "METHOD: (extract_textual_data)\n",
        "as the name suggests this method extracts the textual data from the assessmentQ question data\n",
        "PARAMS:\n",
        "dir_path: path to directory containing the questions you want to process\n",
        "dest_path: path to directory where the processed data needs to be stored\n",
        "===================================================================================================================\n",
        "'''\n",
        "\n",
        "def extract_textual_data(dir_path, dest_path):\n",
        "    if os.path.isdir(dir_path):\n",
        "\n",
        "        # go over all files in the directory\n",
        "        for file_name in tqdm(os.listdir(dir_path)):\n",
        "            if file_name != '.ipynb_checkpoints':\n",
        "                file_path = os.path.join(dir_path, file_name)\n",
        "                file = open(file_path)\n",
        "                json_file = json.load(file)\n",
        "\n",
        "                # Extract & clean textual data from \"Metadata\" > \"Location\"\n",
        "                json_file[\"Location_Cleaned\"] = json_file[\"Metadata\"][\"Location\"].replace('>', ' ')\n",
        "                # Extract & clean textual data from \"Instruction\"\n",
        "                json_file[\"Instruction_Cleaned\"] = BeautifulSoup(json_file['Instruction'], 'html.parser').text\n",
        "                # Extract & clean textual if there is an \"Anwsers\" property present\n",
        "                if 'Answers' in json_file:\n",
        "                    json_file[\"Answers_Cleaned\"] = \"\"\n",
        "                    for i in json_file['Answers']:\n",
        "                        if \"Value\" in i and i[\"Value\"] is not None:\n",
        "                            json_file[\"Answers_Cleaned\"] += BeautifulSoup(i['Value'], 'html.parser').text + '\\n'\n",
        "                        if \"Text\" in i and i[\"Text\"] is not None:\n",
        "                            json_file[\"Textual_data\"] += BeautifulSoup(i['Text'], 'html.parser').text + '\\n'\n",
        "      \n",
        "                # save the data\n",
        "                dest_file_path = os.path.join(dest_path, file_name)\n",
        "                with open(dest_file_path, \"w\") as file:\n",
        "                    json.dump(json_file, file)"
      ],
      "metadata": {
        "id": "G2JNBZhU2qhT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll "
      ],
      "metadata": {
        "id": "NZDad093-sRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_textual_data(\"data\",\"data_text_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts4fmVFa8BFf",
        "outputId": "27ade50b-a41f-4a97-a646-fd681ad5f01d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 649.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_json_helper(\"data_text_extracted/sample.mcq.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCp-40rQ8qWv",
        "outputId": "105dbe57-5d49-4fca-a80c-957706cfa6b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Id\": \"0000FBB0-D511-4151-A468-06F215620C31\",\n",
            "    \"Type\": \"MCQ\",\n",
            "    \"Name\": null,\n",
            "    \"Instruction\": \"<p style=\\\"text-align:justify;font-size:15px;\\\">Which of these rivers is the longest?</p>\",\n",
            "    \"Answers\": [\n",
            "        {\n",
            "            \"Value\": \"<p>Amazon River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 0\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Danube River</p>\",\n",
            "            \"IsCorrect\": true,\n",
            "            \"ChoiceId\": 1\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Nile River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 2\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Hudson River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 3\n",
            "        }\n",
            "    ],\n",
            "    \"Scoring\": {\n",
            "        \"MaxScore\": 10.0,\n",
            "        \"MinScore\": 0.0\n",
            "    },\n",
            "    \"Metadata\": {\n",
            "        \"Language\": \"eng\",\n",
            "        \"Subject\": null,\n",
            "        \"Sector\": \"Secondary Education\",\n",
            "        \"Difficulty\": null,\n",
            "        \"CustomerId\": null,\n",
            "        \"Custom\": [],\n",
            "        \"Location\": \"Content 2021 > ENG > Geography\"\n",
            "    },\n",
            "    \"Location_Cleaned\": \"Content 2021   ENG   Geography\",\n",
            "    \"Instruction_Cleaned\": \"Which of these rivers is the longest?\",\n",
            "    \"Answers_Cleaned\": \"Amazon River\\nDanube River\\nNile River\\nHudson River\\n\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wdKbQiWa90MU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Determine correct language\n",
        "As previously mentioned there is a \"Language\" property present in the data. However during previous research projects it has come to light that this language indication is often incorrect. The language detection tool which was originally used for determining the language of the questions, was not accurate enough (e.g. \"dutch\" was often misinterpreted as \"south-african\"). Therefor we will now correct this by using some availlable toolboxes."
      ],
      "metadata": {
        "id": "2HjGPoWV_XwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. installing and importing necessary libraries"
      ],
      "metadata": {
        "id": "iYbDx3JlGmKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDLBI80TBIoH",
        "outputId": "0f2f667a-720e-4b49-db1a-734e54e175ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=4b246e55541d3f2105293c9d0b82fc24da6ee2f7dc0198455210fb8593e66c92\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "xMxm2E9DGtD9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Language extraction method\n",
        "The following method is a modified version of the method that can be found [here](https://github.com/pieter98/question_metadata/blob/main/pre_processing_methods/language_extractor.py)."
      ],
      "metadata": {
        "id": "A9XFu4t6G3dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "===================================================================================================================\n",
        "METHOD: (extract_language)\n",
        "as the name suggests this method derrives the language from the textual data in the assessmentQ question\n",
        "PARAMS:\n",
        "dir_path:   path to directory containing the questions you want to process\n",
        "dest_path:  path to directory where the processed data needs to be stored\n",
        "===================================================================================================================\n",
        "'''\n",
        "\n",
        "def extract_language(dir_path, dest_path):\n",
        "    translator = Translator()\n",
        "    if os.path.isdir(dir_path):\n",
        "\n",
        "        # iterate over all files in the directory\n",
        "        for file_name in tqdm(os.listdir(dir_path)):\n",
        "            if file_name != '.ipynb_checkpoints':\n",
        "                file_path = os.path.join(dir_path, file_name)\n",
        "                file = open(file_path)\n",
        "                json_file = json.load(file)\n",
        "\n",
        "                # create a voting dictionary\n",
        "                voting_dict = {}\n",
        "\n",
        "                # determine the language for all textual data parts we extracted, each part prediction is a vote for a certain language\n",
        "                if json_file[\"Instruction_Cleaned\"] != \"\":\n",
        "                    pred = translator.detect(json_file[\"Instruction_Cleaned\"]).lang\n",
        "                    if pred in voting_dict:\n",
        "                        voting_dict[pred] += 1\n",
        "                    else:\n",
        "                        voting_dict[pred] = 1\n",
        "                if json_file[\"Answers_Cleaned\"] != \"\":\n",
        "                    pred = translator.detect(json_file[\"Answers_Cleaned\"]).lang\n",
        "                    if pred in voting_dict:\n",
        "                        voting_dict[pred] += 1\n",
        "                    else:\n",
        "                        voting_dict[pred] = 1\n",
        "                if json_file[\"Location_Cleaned\"] != \"\":\n",
        "                    pred = translator.detect(json_file[\"Location_Cleaned\"]).lang\n",
        "                    if pred in voting_dict:\n",
        "                        voting_dict[pred] += 1\n",
        "                    else:\n",
        "                        voting_dict[pred] = 1\n",
        "\n",
        "                # Language with the highest number of votes will be used\n",
        "                if len(voting_dict) !=0:\n",
        "                    json_file[\"Language_Extracted\"] = max(voting_dict, key=voting_dict.get)\n",
        "                else: \n",
        "                    json_file[\"Language_Extracted\"] = null\n",
        "\n",
        "                # save to dest directory\n",
        "                dest_file_path = os.path.join(dest_path, file_name)\n",
        "                with open(dest_file_path, \"w\") as file:\n",
        "                    json.dump(json_file, file)"
      ],
      "metadata": {
        "id": "hdIfMx5SBNVU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll run the method on all files that were already processed by the textual data extractor"
      ],
      "metadata": {
        "id": "O4onqTXQHSXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_language(\"data_text_extracted\",\"data_language_extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GURnBvHxFYUi",
        "outputId": "30b16cd9-2e94-4efb-e75a-5f102d0ad8bc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  6.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_json_helper(\"data_language_extracted/sample.mcq.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cVwa7IhGFyx",
        "outputId": "698129df-a7b5-426c-f389-fec3b3a7f239"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Id\": \"0000FBB0-D511-4151-A468-06F215620C31\",\n",
            "    \"Type\": \"MCQ\",\n",
            "    \"Name\": null,\n",
            "    \"Instruction\": \"<p style=\\\"text-align:justify;font-size:15px;\\\">Which of these rivers is the longest?</p>\",\n",
            "    \"Answers\": [\n",
            "        {\n",
            "            \"Value\": \"<p>Amazon River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 0\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Danube River</p>\",\n",
            "            \"IsCorrect\": true,\n",
            "            \"ChoiceId\": 1\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Nile River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 2\n",
            "        },\n",
            "        {\n",
            "            \"Value\": \"<p>Hudson River</p>\",\n",
            "            \"IsCorrect\": false,\n",
            "            \"ChoiceId\": 3\n",
            "        }\n",
            "    ],\n",
            "    \"Scoring\": {\n",
            "        \"MaxScore\": 10.0,\n",
            "        \"MinScore\": 0.0\n",
            "    },\n",
            "    \"Metadata\": {\n",
            "        \"Language\": \"eng\",\n",
            "        \"Subject\": null,\n",
            "        \"Sector\": \"Secondary Education\",\n",
            "        \"Difficulty\": null,\n",
            "        \"CustomerId\": null,\n",
            "        \"Custom\": [],\n",
            "        \"Location\": \"Content 2021 > ENG > Geography\"\n",
            "    },\n",
            "    \"Location_Cleaned\": \"Content 2021   ENG   Geography\",\n",
            "    \"Instruction_Cleaned\": \"Which of these rivers is the longest?\",\n",
            "    \"Answers_Cleaned\": \"Amazon River\\nDanube River\\nNile River\\nHudson River\\n\",\n",
            "    \"Language_Extracted\": \"en\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data to csv\n",
        "We can now split the data by using the different properties that we added/were already present. \n",
        "\n",
        "- Splitting on sector\n",
        "- Splitting on language\n",
        "- Differentiation of datasets by which text fields are incorporated.\n",
        "- ...\n",
        "\n",
        "We will define a method where which takes a list of options. Based on these options it will generate a .csv file containing all data."
      ],
      "metadata": {
        "id": "aFnkyShrHiN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. importing necessary libraries"
      ],
      "metadata": {
        "id": "PXthTxFKQflU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "RHxNLtZhLeeE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 defining the method"
      ],
      "metadata": {
        "id": "qabmqIMsQtT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "===================================================================================================================\n",
        "METHOD: (data_to_csv)\n",
        "as the name suggests this method will filter the data based on the provided parameters and write the \n",
        "resulting data to a csv file\n",
        "PARAMS:\n",
        "dir_path:               path to directory containing the questions you want to process\n",
        "dest_path:              path to directory where the processed data needs to be stored\n",
        "sector:                 desired sector of the data\n",
        "languague:              desired language of the data\n",
        "textual_data_options:   extra options for the textual data\n",
        "          * answers:    the answer data will be included\n",
        "          * location:   the location data will be included\n",
        "===================================================================================================================\n",
        "'''\n",
        "\n",
        "def data_to_csv(dir_path, dest_path, sector, language, textual_data_options=None):\n",
        "    if os.path.isdir(dir_path):\n",
        "\n",
        "        # creation of csv file with naming convention based on parameters\n",
        "        csv_file_name = \"{}_{}\".format(language, sector.lower().replace(\" \", \"_\"))\n",
        "        if textual_data_options: \n",
        "          for option in textual_data_options: csv_file_name += \"_{}\".format(option)\n",
        "        csv_file_name += \".csv\"\n",
        "        csv_file_path = os.path.join(dest_path, csv_file_name)\n",
        "        csv_file = open(csv_file_path, \"w\")\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "\n",
        "        # iterate over all files in the directory\n",
        "        for file_name in tqdm(os.listdir(dir_path)):\n",
        "            if file_name != '.ipynb_checkpoints':\n",
        "                file_path = os.path.join(dir_path, file_name)\n",
        "                file = open(file_path)\n",
        "                json_file = json.load(file)\n",
        "                \n",
        "                if sector == json_file[\"Metadata\"][\"Sector\"] and language == json_file[\"Language_Extracted\"]:\n",
        "                    row_data = [json_file[\"Id\"]]\n",
        "                    textual_data = json_file[\"Instruction_Cleaned\"]\n",
        "                    if textual_data_options:\n",
        "                        if \"answers\" in textual_data_options:\n",
        "                            textual_data += \"\\n{}\".format(json_file[\"Answers_Cleaned\"])\n",
        "                        if \"location\" in textual_data_options:\n",
        "                            textual_data += \"\\n{}\".format(json_file[\"Location_Cleaned\"])\n",
        "                    row_data.append(textual_data)\n",
        "                    csv_writer.writerow(row_data)\n"
      ],
      "metadata": {
        "id": "Wp2iProkIZQD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll run the method on the preprocessed data (only one sample file here).\n",
        "\n",
        "First with no extra textual_data_options:"
      ],
      "metadata": {
        "id": "VHVhVV_0QzwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_csv(\"data_language_extracted\", \"test\", \"Secondary Education\", \"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFbf6VATMGAn",
        "outputId": "393a2430-db22-40e6-dcc0-56ace1018c76"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1716.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with extra textual data options:"
      ],
      "metadata": {
        "id": "wLOOjjp-SNO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_csv(\"data_language_extracted\", \"test\", \"Secondary Education\", \"en\", textual_data_options=[\"answers\", \"location\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHl8TqCkSW9U",
        "outputId": "e78404af-f977-4247-9c5a-c5af9c86da66"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1300.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting csv files can be found in the destination folder (if this parameter was not changed this will be the \"test\" folder)"
      ],
      "metadata": {
        "id": "ZeKqJZtqSi99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "this notebook briefly illustrated the preprocessing steps which needed to be taken to tranform the raw assessmentQ data into a usuable form and filter the data based on sector and language.\n",
        "\n"
      ],
      "metadata": {
        "id": "j9mb9UD_Svqn"
      }
    }
  ]
}