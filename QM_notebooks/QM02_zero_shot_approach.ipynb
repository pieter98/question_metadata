{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pieter98/question_metadata/blob/main/QM_notebooks/QM02_zero_shot_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUQEqR0vRkco"
      },
      "source": [
        "# Zero-shot approach\n",
        "This notebook contains all code for a zero-shot attempt at \"exam question classification\". \n",
        "\n",
        "Our research revolves around automatically determining the topic of an exam question based on the question instruction and possible answers (e.g. a multiple choice question contains a set of possible answers which can give useful insights into the topic).\n",
        "\n",
        "#### **!! for GDPR reasons the data used in this notebook is limited to only a few anonymised data samples Â¡Â¡**\n",
        "\n",
        "**Problem:**\n",
        "\n",
        "We have a vast amount of data however this data is either not labelled at all or labelled incorrectly.\n",
        "As there is a severe lack of useful, labelled datapoints a zero-shot approach was suggested. This zero-shot approach can then be used for meaningful topic suggestions or create labelled data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility library tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BVZq2Hk2LV2b"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz5pUeaLVGUX"
      },
      "source": [
        "## 1. Hugging Face transformer pipeline\n",
        "The transformers library of Hugging Face has a zero-shot-classification pipeline for NLP ([huggingface discussion](https://huggingface.co/)). Using this pipeline we can easily tryout zero-shot classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1uRMsYwa1R5"
      },
      "source": [
        "### 1.1. Install necessary libraries\n",
        "We'll start off by installing the transformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzGbMxQfU4sZ",
        "outputId": "8e09a3ea-ea85-40cf-e73c-3939122d418d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.19.0\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.2 MB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 78.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.19.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. zero-shot pipeline examples\n",
        "Let's quickly test the zero shot pipeline using some sample data."
      ],
      "metadata": {
        "id": "Ju0g_hJdd75U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Cou2RzbbeZ"
      },
      "source": [
        "#### 1.3.1. Import data\n",
        "As we can't use the assessmentQ dataset directly in this notebook due to GDPR restrictions, so we provided a dummy dataset of (anonymised) exam questions which can be found [here](https://github.com/pieter98/question_metadata/blob/main/data/dataset_en.csv).\n",
        "\n",
        "Let's start by importing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y775MOaNbqQK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU4VmINtbtEa",
        "outputId": "9c8c7aa5-5d9a-48a2-c985-5834209ef7f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Instruction\n",
            "0  Hoite Wigsma a Dutch musician has designed an ...\n",
            "1  Mark the only correct answer Some stars explod...\n",
            "2  Choose the only correct answer Choose the corr...\n",
            "3  A 250 mL vessel contains 0374 g of a gaseous p...\n",
            "4  Mark the only correct answer Which theory of e...\n",
            "                                          Instruction\n",
            "0   Hoite Wigsma a Dutch musician has designed an ...\n",
            "1   Mark the only correct answer Some stars explod...\n",
            "2   Choose the only correct answer Choose the corr...\n",
            "3   A 250 mL vessel contains 0374 g of a gaseous p...\n",
            "4   Mark the only correct answer Which theory of e...\n",
            "5                      What is the capital of France?\n",
            "6   Mark the only correct answer. Which equation s...\n",
            "7   Mark the only correct answer for each row. In ...\n",
            "8   The ICSH hormone is secreted by the In the tes...\n",
            "9   Please mark the only correct answer. Which tri...\n",
            "10  Watch the video How can you explain the functi...\n",
            "11  Type the answer in the empty boxOn a beautiful...\n",
            "12  Indicate the only correct answer In banana fli...\n",
            "13  Write down the excretory organs together with ...\n",
            "14  What is the unit of tension? Mark the correct ...\n",
            "15  What are the neighboring countries of the colo...\n",
            "16  Indicate the only correct answer The position ...\n",
            "17  Indicate the only correct answerWhich Flemish ...\n",
            "18  To connect lamps in parallel, they are connect...\n",
            "19  Type the answer in the empty box In which part...\n",
            "20  Mark the only correct answer What are the thre...\n",
            "21  Type the answer in the empty boxesHow many mol...\n",
            "22  Type the answer in the empty box Anna wears gl...\n",
            "23  Which of the circuits below are series circuit...\n",
            "24  Mark the only correct answerWhich precipitatio...\n",
            "25  Multiple choice questions; mark the correct an...\n",
            "26  Why do some plants catch insects to survive? I...\n",
            "27  Indicate the only correct answer In which geol...\n",
            "28                       Which cities are in Belgium?\n",
            "29  Coordinating effect of hormones Hormones have ...\n",
            "30  Answer the question with the following tableTh...\n",
            "31  Indicate the only correct answerIn June 2018, ...\n",
            "32  What is the importance of the figure Alexander...\n",
            "33  Why was the Babylonian captivity so decisive f...\n",
            "34  Type the answer in the empty box What is Newto...\n",
            "35  Look carefully at the particle model below. Ho...\n",
            "36       Which system can you see in the image below?\n",
            "37  Mark the only correct answer What is the reaso...\n",
            "38  Mark the only correct answerWhich agricultural...\n",
            "39                       A jar of glucose test strips\n",
            "40  Type the answer in the empty box Why do many f...\n",
            "41  Indicate the only correct answer. Benzene has ...\n",
            "42  Enter the correct terminology The light leaves...\n",
            "43  A researcher takes a piece of muscle tissue fr...\n",
            "44  According to the atlas map, how many inhabitan...\n",
            "45  World War I, also called World War I or the Gr...\n",
            "46  Can you use the formula for determining the ma...\n",
            "47  Why is seed dispersal in plants important? Exp...\n",
            "48  Mark the correct answer Explain why large part...\n",
            "49  Type the answer in the empty box. Which organs...\n",
            "50  Enter the answer in the blank box. What temper...\n",
            "51  Type the answer in the blank boxWatch the Alas...\n",
            "52  Indicate the only correct answer Haemophilia i...\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"sample_data/dataset_en.csv\")\n",
        "print(df.head())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2. Example predictions with pipeline\n",
        "Let's do some sample predictions using the pipeline and some predefined labels (\"Chemistry\", \"History\", \"Geography\", \"Physics\", \"Biology\").\n",
        "We start by creating the pipeline and creating a subjects array containing the possible labels.\n",
        "\n",
        "**Note:** by default the pipeline uses the 'facebook/bart-large-mnli' model ([hugging face link](https://huggingface.co/facebook/bart-large-mnli))"
      ],
      "metadata": {
        "id": "iodsoEv6JmaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "subjects = [\"Chemistry\", \"History\", \"Geography\", \"Physics\", \"Biology\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj7VsQEgiJwG",
        "outputId": "fef16aaf-235a-4265-dcf9-0543287ec80a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the created pipeline we can now classify a few of our data samples:"
      ],
      "metadata": {
        "id": "pXvZ94RQPX3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  classification = classifier(df[\"Instruction\"][i], subjects)\n",
        "  print(\"{}) {}\".format(i, classification[\"sequence\"]))\n",
        "  for i in range(len(classification[\"labels\"])):\n",
        "    print(\"\\t{}: {}\".format(classification[\"labels\"][i], classification[\"scores\"][i]))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J667LJYNiu8n",
        "outputId": "99117550-ea84-41d2-a027-7255c066e30a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0) Hoite Wigsma a Dutch musician has designed an organ that works on the waves of the seawater The tones are created because the undulating water forces air through the tubes With a sound sensor and an oscilloscope the tone of the organ is made visible What is the period of this vibration ?\n",
            "\tGeography: 0.28657853603363037\n",
            "\tPhysics: 0.22335126996040344\n",
            "\tHistory: 0.18328404426574707\n",
            "\tChemistry: 0.16544802486896515\n",
            "\tBiology: 0.14133816957473755\n",
            "\n",
            "1) Mark the only correct answer Some stars explode These are supernovae Less than ten of them have been observed on Earth in the past 2000 years Suppose Sirius explodes today When will you see this?\n",
            "\tPhysics: 0.3551057279109955\n",
            "\tHistory: 0.33199506998062134\n",
            "\tChemistry: 0.11198030412197113\n",
            "\tBiology: 0.10627324134111404\n",
            "\tGeography: 0.09464572370052338\n",
            "\n",
            "2) Choose the only correct answer Choose the correct century Prince Philippe became king of Belgium in 2014 This is the ____ century\n",
            "\tHistory: 0.653565526008606\n",
            "\tGeography: 0.12510249018669128\n",
            "\tBiology: 0.07597280293703079\n",
            "\tChemistry: 0.07374654710292816\n",
            "\tPhysics: 0.07161256670951843\n",
            "\n",
            "3) A 250 mL vessel contains 0374 g of a gaseous pure substance at a temperature of 22 degrees and a pressure of 1006 kPa. Which gas could that be?\n",
            "\tPhysics: 0.44096046686172485\n",
            "\tChemistry: 0.19812718033790588\n",
            "\tGeography: 0.150009423494339\n",
            "\tHistory: 0.11590783298015594\n",
            "\tBiology: 0.09499510377645493\n",
            "\n",
            "4) Mark the only correct answer Which theory of evolution does this picture refer to?\n",
            "\tBiology: 0.2944963574409485\n",
            "\tHistory: 0.25368788838386536\n",
            "\tPhysics: 0.15459638833999634\n",
            "\tChemistry: 0.15058648586273193\n",
            "\tGeography: 0.14663290977478027\n",
            "\n",
            "5) What is the capital of France?\n",
            "\tGeography: 0.8394460678100586\n",
            "\tHistory: 0.06927629560232162\n",
            "\tChemistry: 0.03476666659116745\n",
            "\tBiology: 0.030660655349493027\n",
            "\tPhysics: 0.025850269943475723\n",
            "\n",
            "6) Mark the only correct answer. Which equation shows the dissolution process of NaHCO in water?\n",
            "\tChemistry: 0.45591211318969727\n",
            "\tPhysics: 0.29185473918914795\n",
            "\tBiology: 0.1293213814496994\n",
            "\tHistory: 0.07553991675376892\n",
            "\tGeography: 0.04737180471420288\n",
            "\n",
            "7) Mark the only correct answer for each row. In which flower diagram do you see 4 congealed petals?\n",
            "\tBiology: 0.26027244329452515\n",
            "\tGeography: 0.21087004244327545\n",
            "\tHistory: 0.18479759991168976\n",
            "\tChemistry: 0.18352149426937103\n",
            "\tPhysics: 0.16053839027881622\n",
            "\n",
            "8) The ICSH hormone is secreted by the In the testicle the ICSH hormone acts on the cells of In these interstitial cells the ICSH hormone stimulates the production of The latter hormone ensures the maintenance of the male reproductive system the male forms and sperm production\n",
            "\tBiology: 0.5976043939590454\n",
            "\tChemistry: 0.1252855807542801\n",
            "\tHistory: 0.11995045840740204\n",
            "\tGeography: 0.09316873550415039\n",
            "\tPhysics: 0.06399084627628326\n",
            "\n",
            "9) Please mark the only correct answer. Which tribe of Kenya that mainly focuses on animal husbandry is often visited by tourists?\n",
            "\tHistory: 0.3951553404331207\n",
            "\tGeography: 0.2577207684516907\n",
            "\tBiology: 0.14447021484375\n",
            "\tChemistry: 0.12647010385990143\n",
            "\tPhysics: 0.07618358731269836\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This small sample size of datapoints gives us promising results. We can see that for most questions the model gives a reasonable predictions, e.g.:\n",
        "\n",
        "- the question \"What is the capital of France?\" has Geography as label with the highest probability\n",
        "- question 6 has \"Chemistry\" as its highest probability which is a reasonable prediction.\n",
        "- ...\n",
        "\n",
        "If the label probabilities seem to be incorrect (not what was expected), we can also derrive the reason for the \"incorrect\" classifications. E.g. question 1 has \"Geography\" as its most probable label however when reading the question, we would classify the topic to be Physics (which is the second highest probability). The high probability for \"Geography\" could be related to the presence of words such as \"seawater, period, ...\" which can be linked to the topic.\n",
        "\n",
        "Conclusion: even the faulty predictions make some kind of sense\n"
      ],
      "metadata": {
        "id": "XKxZZ-zkVwUv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np1iqVixXMf9"
      },
      "source": [
        "### 1.4. Measuring the accuracy of zero-shot learning\n",
        "\n",
        "How do we measure the accuracy for the zero-shot learning approach? Zero-shot learning, inherently, does not use labeled data. It has no training phase where the model is optimized using a loss function, a validation set, test set, ... . \n",
        "\n",
        "To have some semblance of the accuracy of zero-shot learning we can label our data, establish a ground truth, and compare the top prediciton(s) of the zero-shot learning model to the correct label.\n",
        "\n",
        "**However** manually labeling the existing data is a very time consuming task. Therefor we will leverage some existing machine learning based toolboxes to make this process easier."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Using BERTopic to label a subset of our data\n",
        "\n",
        "*BERTopic is a toolbox that we used to quickly label a substantial amount of our data. This part consists of a small demo of the toolbox used on a public dataset as an illustration of its functionalities.Our own dataset is not used for this part as google collab crashed multiple times when loading in the data. In the end remarks of this section we've provided a link to a csv file which contain the results of BERTopic used on our own dataset.*\n",
        "\n",
        "**From the [BERTopic website](https://maartengr.github.io/BERTopic/index.html):**\n",
        "\n",
        "BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
        "\n",
        "BERTopic supports guided, (semi-) supervised, and dynamic topic modeling. It even supports visualizations similar to LDAvis!\n",
        "\n",
        "\n",
        "**In short**: the BERTopic toolbox allows us to cluster documents together based on their keywords. If we assign topic labels to these clusters we can label data in bulk (as question with the same distinguishable keywords can be categorised under the same topic). \n",
        "\n",
        "Let's do a quick demo of BERTopic using the skleurn 20 newsgroups dataset:"
      ],
      "metadata": {
        "id": "5653R9t35gzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Installing BERTopic"
      ],
      "metadata": {
        "id": "N4_JKlR0-SMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mytYWWFAXo5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b487ff-caea-42c1-ea93-7380f45cfb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pyyaml<6.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (5.4.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (5.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.0.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (2.2.0)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.3.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (4.64.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.28 in /usr/local/lib/python3.7/dist-packages (from bertopic) (0.8.28)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (0.29.30)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.12.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.11.0+cu113)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.19.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (4.2.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.0->bertopic) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.7)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKRzVMYuAnbI",
        "outputId": "06ac4867-329f-47fe-a1eb-07fd13def8ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Importing BERTopic and the dummy data\n",
        "\n",
        "Let's create our BERTopic model:"
      ],
      "metadata": {
        "id": "o1sMDj6k-IPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic()"
      ],
      "metadata": {
        "id": "TfZEIBAJ-6Aj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import our data:"
      ],
      "metadata": {
        "id": "CDczLtUg_VWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
      ],
      "metadata": {
        "id": "Vhb9ciLL_XIb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Generating topics\n",
        "\n",
        "Based on the dataset we can generate BERTopic topics (groupings based on keywords):"
      ],
      "metadata": {
        "id": "cX3velJx_ex-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics, probs = topic_model.fit_transform(docs)"
      ],
      "metadata": {
        "id": "2lJZM1ws_0Nt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fitting the model we can print topic info:"
      ],
      "metadata": {
        "id": "X-hzRpzNAGKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ds-zefDDAQWr",
        "outputId": "a677f09d-5dc8-4b35-d11e-14bd0d395be2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Topic  Count                                          Name\n",
              "0       -1   6391                               -1_to_the_is_of\n",
              "1        0   1836                          0_game_team_games_he\n",
              "2        1    612                 1_key_clipper_chip_encryption\n",
              "3        2    531                          2_ites_cheek_yep_huh\n",
              "4        3    486                    3_israel_israeli_jews_arab\n",
              "..     ...    ...                                           ...\n",
              "221    220     10                     220_610_iivx_c610_centris\n",
              "222    221     10                  221_seizure_seizures_corn_sp\n",
              "223    222     10            222_rape_female_statutes_underwear\n",
              "224    223     10          223_religion_justifiable_war_history\n",
              "225    224     10  224_8051_assembler_signetics_microcontroller\n",
              "\n",
              "[226 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae4df58b-4824-4b86-bb11-e70519436e91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>6391</td>\n",
              "      <td>-1_to_the_is_of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1836</td>\n",
              "      <td>0_game_team_games_he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>612</td>\n",
              "      <td>1_key_clipper_chip_encryption</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>531</td>\n",
              "      <td>2_ites_cheek_yep_huh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>486</td>\n",
              "      <td>3_israel_israeli_jews_arab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>220</td>\n",
              "      <td>10</td>\n",
              "      <td>220_610_iivx_c610_centris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>221</td>\n",
              "      <td>10</td>\n",
              "      <td>221_seizure_seizures_corn_sp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>222</td>\n",
              "      <td>10</td>\n",
              "      <td>222_rape_female_statutes_underwear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>223</td>\n",
              "      <td>10</td>\n",
              "      <td>223_religion_justifiable_war_history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>224</td>\n",
              "      <td>10</td>\n",
              "      <td>224_8051_assembler_signetics_microcontroller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4df58b-4824-4b86-bb11-e70519436e91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae4df58b-4824-4b86-bb11-e70519436e91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae4df58b-4824-4b86-bb11-e70519436e91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** group -1 are all documents who could not be assigned to a cluster"
      ],
      "metadata": {
        "id": "0-m3zwVAHxd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 BERTopic on our own data\n",
        "\n",
        "An example of BERTopic run on our own data can be found [here](https://github.com/pieter98/question_metadata/blob/main/data/BERTopic_example_dutch.xlsx).\n",
        "\n",
        "As stated before, BERTopic is used as a tool to make bulk labeling possible. We used it to group our data based on keywords and if the keywords were logically related to a topic, we would assign this topic to the whole group.\n",
        "\n",
        "Example from the BERTopic results:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Group 7 can clearly be identified as being related to electricity/physics. Therefor we assign these labels to all questions clustered within this group.\n",
        "\n",
        "...\n",
        "\n"
      ],
      "metadata": {
        "id": "UyQtYFTHECjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Accuracy measures for zero-shot learning\n",
        "\n",
        "We have a labeled subset of our data (obtained by using BERTopic or manual labelling). We can now start some accuracy/useability measures for our zero-shot classification.\n",
        "\n",
        "Let's start by loading our labeled subset of data *(a small anonymised dataset is used in this notebook).*"
      ],
      "metadata": {
        "id": "Wd1v0HF6IUWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_labeled = pd.read_csv(\"sample_data/dataset_en_labeled.csv\", delimiter=\";\")\n",
        "df_labeled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cqVhCbfTJkOu",
        "outputId": "22701d6c-172f-4aeb-f9f3-102378ccb500"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Instruction      Label\n",
              "0  Hoite Wigsma a Dutch musician has designed an ...    Physics\n",
              "1  Mark the only correct answer Some stars explod...  Geography\n",
              "2  Choose the only correct answer Choose the corr...    History\n",
              "3  A 250 mL vessel contains 0374 g of a gaseous p...  Chemistry\n",
              "4  Mark the only correct answer Which theory of e...    Biology"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2c60b60-bb98-4945-a794-19c54ff9bfa4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Instruction</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hoite Wigsma a Dutch musician has designed an ...</td>\n",
              "      <td>Physics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mark the only correct answer Some stars explod...</td>\n",
              "      <td>Geography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Choose the only correct answer Choose the corr...</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A 250 mL vessel contains 0374 g of a gaseous p...</td>\n",
              "      <td>Chemistry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mark the only correct answer Which theory of e...</td>\n",
              "      <td>Biology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2c60b60-bb98-4945-a794-19c54ff9bfa4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2c60b60-bb98-4945-a794-19c54ff9bfa4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2c60b60-bb98-4945-a794-19c54ff9bfa4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1.  Is the most probable label correct?\n",
        "\n",
        "A simple measure is checking wether the label with the highest probability is the same as the one we personally assigned to the question. Let's create a zero-shot classification pipeline and count how many times it predictions are correct."
      ],
      "metadata": {
        "id": "9z_1wg6GJMMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "subjects = [\"Chemistry\", \"History\", \"Geography\", \"Physics\", \"Biology\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kntE9jZMKdxD",
        "outputId": "f0503f66-9d6f-4291-8f8b-6da415776cb3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count = 0\n",
        "for index, row in tqdm(df_labeled.iterrows()):\n",
        "  classification = classifier(row[\"Instruction\"], subjects)\n",
        "  if classification[\"labels\"][0] == row[\"Label\"]:\n",
        "    correct_count = correct_count + 1\n",
        "correct_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-losDQfjKumJ",
        "outputId": "e14d21bd-0586-4e0c-e948-3cf2a0409001"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "49it [03:18,  4.05s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Overall accuracy is {}%\".format(round(correct_count/df_labeled.shape[0]*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIjbsi84Mu26",
        "outputId": "f65043ae-3d56-475a-e540-f2bae25a7d61"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy is 67.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get an accuracy of 67.35%, which isn't bad! However a connotation has to be made, the subjects array is limited to only 5 topics/subjects that occur in our labeled sub-dataset.\n",
        "\n",
        "Let's see what happens when we increase the amount of possible topics/subjects. After all, secondary education isn't limited to \"Chemistry\", \"History\", \"Geography\", \"Physics\" and \"Biology\"."
      ],
      "metadata": {
        "id": "yTcZbqdbNYUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = [\"Chemistry\", \"History\", \"Geography\", \"Physics\", \"Biology\", \"Mathematics\", \"English\", \"Religion\", \"Physical Education\", \"German\", \"Dutch\", \"French\", \"Latin\", \"Greek\"]"
      ],
      "metadata": {
        "id": "3kCNw3oYOSz1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count = 0\n",
        "for index, row in tqdm(df_labeled.iterrows()):\n",
        "  classification = classifier(row[\"Instruction\"], subjects)\n",
        "  if classification[\"labels\"][0] == row[\"Label\"]:\n",
        "    correct_count = correct_count + 1\n",
        "correct_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lvS4fLiO0ZV",
        "outputId": "e1dc597c-e501-4318-f47d-742bb6deb33a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "49it [08:29, 10.40s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Overall accuracy is {}%\".format(round(correct_count/df_labeled.shape[0]*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk5C83Z8O4SV",
        "outputId": "d5b8a68a-bd42-40c1-ecfd-5de04d26023a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy is 30.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we increasing the amount of subjects from 5 to 14, the accuracy drops by approx. 37%."
      ],
      "metadata": {
        "id": "4Bb7k4EtQ-NS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Accuracy for top-n labels\n",
        "\n",
        "What if we not limit ourselves to only one label but instead take the top-n labels of the prediction? Can we counteract the decrease in accuracy when there are more possible subjects if we take more top predictions into account?\n",
        "\n",
        "Lets start by checking out the top-2 labels:\n"
      ],
      "metadata": {
        "id": "8XA1kwWURVTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count_1 = 0\n",
        "correct_count_2 = 0\n",
        "correct_count_3 = 0\n",
        "correct_count_4 = 0\n",
        "correct_count_5 = 0\n",
        "for index, row in tqdm(df_labeled.iterrows()):\n",
        "  classification = classifier(row[\"Instruction\"], subjects)\n",
        "  if row[\"Label\"] == classification[\"labels\"][0]:\n",
        "    correct_count_1 = correct_count_1 + 1\n",
        "  if row[\"Label\"] in classification[\"labels\"][0:2]:\n",
        "    correct_count_2 = correct_count_2 + 1\n",
        "  if row[\"Label\"] in classification[\"labels\"][0:3]:\n",
        "    correct_count_3 = correct_count_3 + 1\n",
        "  if row[\"Label\"] in classification[\"labels\"][0:4]:\n",
        "    correct_count_4 = correct_count_4 + 1\n",
        "  if row[\"Label\"] in classification[\"labels\"][0:5]:\n",
        "    correct_count_5 = correct_count_5 + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZuXSFcpRvlu",
        "outputId": "85ef8ba4-4664-406d-a93c-ea5dcd2d97d7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "49it [09:25, 11.55s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "scale = df_labeled.shape[0]\n",
        "# Bring some raw data.\n",
        "percentages = [correct_count_1/scale*100, correct_count_2/scale*100, correct_count_3/scale*100, correct_count_4/scale*100, correct_count_5/scale*100]\n",
        "# In my original code I create a series and run on that,\n",
        "# so for consistency I create a series from the list.\n",
        "percentages_series = pd.Series(percentages)\n",
        "\n",
        "\n",
        "\n",
        "# Plot the figure.\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = percentages_series.plot(kind=\"bar\")\n",
        "ax.set_title(\"Accuracy for top-n labels\")\n",
        "ax.set_xlabel(\"Top-n\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "\n",
        "rects = ax.patches\n",
        "\n",
        "# Make some labels.\n",
        "labels = [f\"n = {i+1}\" for i in range(5)]\n",
        "\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(\n",
        "        rect.get_x() + rect.get_width() / 2, height + 0.5, label, ha=\"center\", va=\"bottom\"\n",
        "    )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "lONrqMTiX6nL",
        "outputId": "07068296-013a-4e19-87cd-c54b5e524218"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAHsCAYAAAApV5CPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df9zldV3n/+fLGR1JqNEEQtCG3dEcsLxkZlGLdTMXghV/k6ajUiFsu9TqtyjZH7esbnWTlX7obu1ulCmr48+hxMRIFiXTSgWhYkIbs8tAEcaCEB2UH6/vH+czdDkzzOdC5lznmpn7/Xab23U+n/M5n/O6rrlu48MP73NOdXcAAID79qBZDwAAAMudaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGWAZq6r/UFU3VdXtVfXts55nb6qqH6mqjyzy2J+vqrd+k8/zTT8WYAfRDOyzquqKqrqlqlbNepZpqKoHJ/m1JCd198Hd/Q974ZzzVfVvH/h0AAcW0Qzsk6pqTZJ/naSTPHuJn3vlEj3V4UkemmTL/X1gTfg3HmAv8Q8qsK96eZI/T/LmJKcvvKOqHl1Vv1dV26rqH6rqNxbcd2ZVXVdVX66qv66q44b9XVVrFxz35qr6peH291fVDVX16qr6YpI3VdXDq+p9w3PcMtw+asHjH1FVb6qqLwz3v2fYf21VPWvBcQ+uqi9V1ZN2+h4el+TTw+atVfXBYf/3VtUnquqfhq/fu+AxV1TVL1fVR5N8Ncm/2Omcb0nymCR/MCz3+Nlh/7OraktV3TqcY92Cx8xX1X8efla3DN/TQ+/rL2U4/pyq+sthxnfu6fidHvuGqrq+qm6rqquq6l/vdMhDh/N9uao+WVVPXPDYR1XVRcPfx99V1X+6j+d4aFW9dfi9uHX4GR6+mPmAA5toBvZVL0+yafjzgzvCp6pWJHlfks8lWZPkyCTvGO77oSQ/Pzz2WzO5Qr3YJQ/fkeQRSb4zyVmZ/Pv5pmH7MUm2J/mNBce/Jcm3JDk2yWFJfn3Y/3+TvHTBcf8uyY3dffXCJ+vuvxkemySru/sHquoRSS5J8j+SfHsmSzcu2Wmt88uG+Q4ZfgYLz/myJH+f5FnDco/XDXH+9iSvSnJokvdnEtUPWfDQjUl+MMm/TPK4JP9tjz+p5IVJTk5ydJLvSfIjI8fv8Ikkc5n8nN+W5N07Bfdzkrx7wf3vGf5Px4OS/EGSv8jk7/sZSV5VVT+4m+c4Pcm3JXl0Jj/DH8/k7w5gj0QzsM+pqhMyidV3dfdVSf42yUuGu49P8qgkP9PdX+nuO7p7x4vNXpHkdd39iZ74THd/bpcn2L17krymu7/W3du7+x+6+6Lu/mp3fznJLyf5N8N8RyQ5JcmPd/ct3X1nd//xcJ63Jvl3VfWtw/bLMgnsxXhmkq3d/Zbuvqu7357kU0meteCYN3f3luH+OxdxzhcluaS7LxuO/5UkByX53gXH/EZ3X9/d/zh8ny8eOef/6O4vDMf/QSYhPKq73zr8XO/q7l9NsirJdy045Kru3jzM+WuZLF15SpJ/leTQ7v7F7v56d382yW8n+eHdPM2dmcTy2u6+u7uv6u7bFjMfcGATzcC+6PQkH+juLw3bb8s/L9F4dJLPdfddu3ncozMJ7G/Gtu6+Y8dGVX1LVf1WVX2uqm5L8uEkq4cr3Y9O8o/dfcvOJ+nuLyT5aJIXVNXqTOJ60yJneFR2uno8bB+5YPv6RX9Huzlnd98znOO+zvm54TGpqj8clnncXlUbFxzzxQW3v5rk4MUMMizruG5Y1nFrJleEH7m7OYY5bxhm+c4kjxqWW9w6PPa/ZLImfGdvSfJHSd4xLJ153fCCS4A9WqoXswDsFVV1UCb/+X/FsL44mVyRXD2scb0+yWOqauVuwvn6TJYY7M5XM1lOscN3ZBJlO/ROx/90JldBn9zdX6yquSRXJ6nheR5RVau7+9bdPNeFmVz1Xpnkz7r78/f9HX+DL2QSiAs9Jsmle5hzZzvf/4Uk371jo6oqk+hfONOjd3q+LyRJd58yPvLiDOuXfzaTpRVbuvueqrolk5/nLnMMSzKOGma5K8nfdfdjx55nuEr9C0l+oSYvJn1/JmvH37h3vhNgf+VKM7CveW6Su5Mck8l/9p9Lsi7Jn2SyVvnjSW5Mcl5VPWx44df3DY/9nSTnVNX6mlhbVTsi9JokL6mqFVV1coalFntwSCZrYW8d1hq/Zscd3X1jkj9M8r+GFww+uKqetuCx70lyXJJXZrLGebHen+RxVfWSqlpZVS8afg7vux/nuCnf+ALBdyV5ZlU9Y7ji+tNJvpbkTxccc3ZVHTV8n/81yTvvx/Mt1iGZxO+2JCur6ucyWXe+0Pqqen5N3r3kVcOcf57J3/mXa/JCzYOGv8MnVNW/2vlJqurpVfXdw38RuC2T5Rr3TOH7AfYzohnY15ye5E3d/ffd/cUdfzJ5Ed7GTK5MPivJ2kxe9HZDJut2093vzmRN7tuSfDmTeH3EcN5XDo+7dTjPe0bmeH0ma3+/lEm4XbrT/S/LJMg+leTmTCIvwxzbk1yUyQvlfm+x3/jwPs2nZhK2/5DJldlTFyxTWYzXJvlvwzKGc7r705m8MPF/Dt/LszJ5oeDXFzzmbUk+kOSzmSxv+aX78XyL9UeZ/Az/JpMlIHdk16UmF2fyd3lLJj/f5w/rxe/O5Ocyl+Tvhu/jdzJZ3rGz70iyOZNgvi7JH2fxa8qBA1h1j/2XPAD2tuFK6uO6+6WjB89QVc0neUV3/79ZzwIwS9Y0AyyxYZnDGZlcLQVgH2B5BsASqqozM1l28Ifd/eFZzwPA4lieAQAAI1xpBgCAEaIZAABG7BMvBHzkIx/Za9asmfUYAADsx6666qovdfehu7tvn4jmNWvW5Morr5z1GAAA7Meq6nP3dZ/lGQAAMEI0AwDACNEMAAAjRDMAAIwQzQAAMEI0AwDAiH3iLecAAJidNWvW5JBDDsmKFSuycuXKA/KtgEUzAACjPvShD+WRj3zkrMeYGcszAAD2E/Pz81m3bl3OPPPMHHvssTnppJOyffv2WY+1XxDNAAD7ka1bt+bss8/Oli1bsnr16lx00UW7HLNp06bMzc3t8ue0007b7TmrKieddFLWr1+fCy64YNrfwrJkeQYAwH7k6KOPztzcXJJk/fr1mZ+f3+WYjRs3ZuPGjYs+50c+8pEceeSRufnmm3PiiSfm8Y9/fJ72tKftrZH3CaIZAGA/smrVqntvr1ixYrfLMzZt2pTzzz9/l/1r167N5s2bd9l/5JFHJkkOO+ywPO95z8vHP/5x0QwAwP7t/lxp/spXvpJ77rknhxxySL7yla/kAx/4QH7u535uyhMuP6IZAID7dNNNN+V5z3tekuSuu+7KS17ykpx88skznmrpVXfPeoZRGzZs6APx/QABAFg6VXVVd2/Y3X3ePQMAAEaIZgAAGCGaAQBghBcCAgDMyJpzL5n1CMvG/HnPnPUIe+RKMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwQjQDAMAI0QwAACNEMwAAjBDNAAAwYqrRXFWrq2pzVX2qqq6rqqdW1SOq6rKq2jp8ffg0ZwAAgAdq2lea35Dk0u5+fJInJrkuyblJLu/uxya5fNgGAIBla2rRXFXfluRpSd6YJN399e6+Nclzklw4HHZhkudOawYAANgbpnml+egk25K8qaqurqrfqaqHJTm8u28cjvliksN39+CqOquqrqyqK7dt2zbFMQEAYM+mGc0rkxyX5H9395OSfCU7LcXo7k7Su3twd1/Q3Ru6e8Ohhx46xTEBAGDPphnNNyS5obs/NmxvziSib6qqI5Jk+HrzFGcAAIAHbGrR3N1fTHJ9VX3XsOsZSf46yXuTnD7sOz3JxdOaAQAA9oaVUz7/TybZVFUPSfLZJD+aSai/q6rOSPK5JC+c8gwAAPCATDWau/uaJBt2c9czpvm8AACwN/lEQADgG9x999150pOelFNPPXXWo8CyIZoBgG/whje8IevWrZv1GLCsiGYA2AfNz89n3bp1OfPMM3PsscfmpJNOyvbt2x/weW+44YZccsklecUrXrEXpoT9h2gGgH3U1q1bc/bZZ2fLli1ZvXp1Lrrool2O2bRpU+bm5nb5c9ppp+32nK961avyute9Lg96kESAhab97hkAwJQcffTRmZubS5KsX78+8/PzuxyzcePGbNy4cVHne9/73pfDDjss69evzxVXXLEXJ4V9n2gGgH3UqlWr7r29YsWK3S7P2LRpU84///xd9q9duzabN2/+hn0f/ehH8973vjfvf//7c8cdd+S2227LS1/60rz1rW/d+8PDPkY0A8B+7P5caX7ta1+b1772tUmSK664Ir/yK78imGFgwRIAAIyo7p71DKM2bNjQV1555azHAADYq9ace8msR1g25s975qxHSFVd1d27+2A+V5oBAGCMaAYAgBGiGQAARnj3DABYAtau/rPlsHYV7i9XmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZAABGiGYAABghmgEAYIRoBgCAEaIZ4AB0xx135Pjjj88Tn/jEHHvssXnNa14z65EAlrWVsx4AgKW3atWqfPCDH8zBBx+cO++8MyeccEJOOeWUPOUpT5n1aADLkivNAMvc/Px81q1blzPPPDPHHntsTjrppGzfvv0BnbOqcvDBBydJ7rzzztx5552pqr0xLsB+aarRXFXzVfVXVXVNVV057HtEVV1WVVuHrw+f5gwA+4OtW7fm7LPPzpYtW7J69epcdNFFuxyzadOmzM3N7fLntNNO2+0577777szNzeWwww7LiSeemCc/+cnT/jYA9llLsTzj6d39pQXb5ya5vLvPq6pzh+1XL8EcAPuso48+OnNzc0mS9evXZ35+fpdjNm7cmI0bNy76nCtWrMg111yTW2+9Nc973vNy7bXX5glPeMLeGhlgvzKLNc3PSfL9w+0Lk1wR0QywR6tWrbr39ooVK3a7PGPTpk05//zzd9m/du3abN68+T7PvXr16jz96U/PpZdeKpoB7sO0o7mTfKCqOslvdfcFSQ7v7huH+7+Y5PDdPbCqzkpyVpI85jGPmfKYAPu++3Oledu2bXnwgx+c1atXZ/v27bnsssvy6le7fgFwX6YdzSd09+er6rAkl1XVpxbe2d09BPUuhsC+IEk2bNiw22MA+ObceOONOf3003P33XfnnnvuyQtf+MKceuqpsx4LYNmaajR39+eHrzdX1e8nOT7JTVV1RHffWFVHJLl5mjMA7OvWrFmTa6+99t7tc8455wGf83u+53ty9dVXP+DzABwopvbuGVX1sKo6ZMftJCcluTbJe5OcPhx2epKLpzUDAADsDdO80nx4kt8f3vdzZZK3dfelVfWJJO+qqjOSfC7JC6c4AwAAPGBTi+bu/mySJ+5m/z8keca0nhcAAPY2nwgIAAAjZvE+zQD7tTXnXjLrEZaN+fOeOesRAPYKV5oBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZphP3f99dfn6U9/eo455pgce+yxecMb3jDrkQBgn7Ny1gMA07Vy5cr86q/+ao477rh8+ctfzvr163PiiSfmmGOOmfVoALDPcKUZlpH5+fmsW7cuZ555Zo499ticdNJJ2b59+wM65xFHHJHjjjsuSXLIIYdk3bp1+fznP783xgWAA4ZohmVm69atOfvss7Nly5asXr06F1100S7HbNq0KXNzc7v8Oe200/Z47vn5+Vx99dV58pOfPK3xAWC/ZHkGLDNHH3105ubmkiTr16/P/Pz8Lsds3LgxGzduvF/nvf322/OCF7wgr3/96/Ot3/qte2NUADhgiGZYZlatWnXv7RUrVux2ecamTZty/vnn77J/7dq12bx58y7777zzzrzgBS/Ixo0b8/znP3/vDgwABwDRDPug+3OlubtzxhlnZN26dfmpn/qpKU8GAPsna5phP/fRj340b3nLW/LBD37w3rXP73//+2c9FgDsU1xphmVkzZo1ufbaa+/dPueccx7wOU844YR09wM+DwAcyFxpBgCAEaIZAABGiGYAABghmgEAYIQXAsIDsObcS2Y9wrIxf94zZz0CAEyNK80AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwAjRDAAAI0QzAACMEM0AADBCNAMAwIipR3NVraiqq6vqfcP20VX1sar6TFW9s6oeMu0ZAADggViKK82vTHLdgu3/nuTXu3ttkluSnLEEMwAAwDdtqtFcVUcleWaS3xm2K8kPJNk8HHJhkudOcwYAAHigpn2l+fVJfjbJPcP2tye5tbvvGrZvSHLklGcAAIAHZGrRXFWnJrm5u6/6Jh9/VlVdWVVXbtu2bS9PBwAAizfNK83fl+TZVTWf5B2ZLMt4Q5LVVbVyOOaoJJ/f3YO7+4Lu3tDdGw499NApjgkAAHs2tWju7v/c3Ud195okP5zkg929McmHkpw2HHZ6kounNQMAAOwNs3if5lcn+amq+kwma5zfOIMZAABg0VaOH/LAdfcVSa4Ybn82yfFL8bwAALA3+ERAAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGj0VxVz6oqcQ0AwAFrMTH8oiRbq+p1VfX4aQ8EAADLzWg0d/dLkzwpyd8meXNV/VlVnVVVh0x9OgAAWAYWteyiu29LsjnJO5IckeR5ST5ZVT85xdkAAGBZWMya5mdX1e8nuSLJg5Mc392nJHlikp+e7ngAADB7KxdxzAuS/Hp3f3jhzu7+alWdMZ2xAABg+VhMNP98kht3bFTVQUkO7+757r58WoMBAMBysZg1ze9Ocs+C7buHfQAAcEBYTDSv7O6v79gYbj9keiMBAMDyspho3lZVz96xUVXPSfKl6Y0EAADLy2LWNP94kk1V9RtJKsn1SV4+1akAAGAZGY3m7v7bJE+pqoOH7dunPhUAACwji7nSnKp6ZpJjkzy0qpIk3f2LU5wLAACWjcV8uMn/SfKiJD+ZyfKMH0rynVOeCwAAlo3FvBDwe7v75Ulu6e5fSPLUJI+b7lgAALB8LCaa7xi+frWqHpXkziRHTG8kAABYXhazpvkPqmp1kvOTfDJJJ/ntqU4FAADLyB6juaoelOTy7r41yUVV9b4kD+3uf1qS6QAAYBnY4/KM7r4nyW8u2P6aYAYA4ECzmDXNl1fVC2rHe80BAMABZjHR/O+TvDvJ16rqtqr6clXdNuW5AABg2VjMJwIeshSDAADAcjUazVX1tN3t7+4P7/1xAABg+VnMW879zILbD01yfJKrkvzAVCYCAIBlZjHLM561cLuqHp3k9VObCAAAlpnFvBBwZzckWbe3BwEAgOVqMWua/2cmnwKYTCJ7LpNPBgQAgAPCYtY0X7ng9l1J3t7dH53SPAAAsOwsJpo3J7mju+9OkqpaUVXf0t1fne5oAACwPCzqEwGTHLRg+6Ak/2864wAAwPKzmGh+aHffvmNjuP0t0xsJAACWl8VE81eq6rgdG1W1Psn26Y3EA/FjP/ZjOeyww/KEJzxh1qMAAOw3FhPNr0ry7qr6k6r6SJJ3JvmJ6Y7FN+tHfuRHcumll856DACA/cpiPtzkE1X1+CTfNez6dHffOd2x9n/z8/M55ZRTcsIJJ+RP//RPc+SRR+biiy/OQQcdNP7gPXja056W+fn5vTMkAABJFnGluarOTvKw7r62u69NcnBV/cfpj7b/27p1a84+++xs2bIlq1evzkUXXbTLMZs2bcrc3Nwuf0477bQZTAwAcGBazFvOndndv7ljo7tvqaozk/yv6Y11YDj66KMzNzeXJFm/fv1urxBv3LgxGzduXOLJAABYaDHRvKKqqrs7mbxPc5KHTHesA8OqVavuvb1ixYps377r6ys3bdqU888/f5f9a9euzebNm6c6HwAAE4uJ5kuTvLOqfmvY/vdJ/nB6I7GQK80AALO3mHfPeHWSDyb58eHPX+UbP+yEZeTFL35xnvrUp+bTn/50jjrqqLzxjW+c9UgAAPu8xbx7xj1V9bEk/zLJC5M8Msmur1jjflmzZk2uvfbae7fPOeecvXLet7/97XvlPAAA/LP7jOaqelySFw9/vpTJ+zOnu5++NKMBAMDysKcrzZ9K8idJTu3uzyRJVf1/SzIVAAAsI3ta0/z8JDcm+VBV/XZVPSNJLc1YAACwfNznlebufk+S91TVw5I8J5OP0z6sqv53kt/v7g8s0YzLwppzL5n1CMvG/HnPnPUIAABLavTdM7r7K939tu5+VpKjklydyTtq7FFVPbSqPl5Vf1FVW6rqF4b9R1fVx6rqM1X1zqryns8AACxri3nLuXt19y3dfUF3P2MRh38tyQ909xOTzCU5uaqekuS/J/n17l6b5JYkZ9zfoQEAYCndr2i+P3ri9mHzwcOfTvIDSXZ8lN2FSZ47rRkAAGBvmFo0J5OP3K6qa5LcnOSyJH+b5Nbuvms45IYkR97HY8+qqiur6spt27ZNc0wAANijqUZzd9/d3XOZrIU+Psnj78djL+juDd294dBDD53ajAAAMGaq0bxDd9+a5ENJnppkdVXteNeOo5J8filmAACAb9bUormqDq2q1cPtg5KcmOS6TOL5tOGw05NcPK0ZAABgb9jTJwI+UEckubCqVmQS5+/q7vdV1V8neUdV/VImb1/3xinOAAAAD9jUorm7/zLJk3az/7OZrG8GAIB9wpKsaQYAgH2ZaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBFTi+aqenRVfaiq/rqqtlTVK4f9j6iqy6pq6/D14dOaAQAA9oZpXmm+K8lPd/cxSZ6S5OyqOibJuUku7+7HJrl82AYAgGVratHc3Td29yeH219Ocl2SI5M8J8mFw2EXJnnutGYAAIC9YUnWNFfVmiRPSvKxJId3943DXV9McvhSzAAAAN+sqUdzVR2c5KIkr+ru2xbe192dpO/jcWdV1ZVVdeW2bdumPSYAANynqUZzVT04k2De1N2/N+y+qaqOGO4/IsnNu3tsd1/Q3Ru6e8Ohhx46zTEBAGCPpvnuGZXkjUmu6+5fW3DXe5OcPtw+PcnF05oBAAD2hpVTPPf3JXlZkr+qqmuGff8lyXlJ3lVVZyT5XJIXTnEGAAB4wKYWzd39kSR1H3c/Y1rPCwAAe5tPBAQAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYMbVorqrfraqbq+raBfseUVWXVdXW4evDp/X8AACwt0zzSvObk5y8075zk1ze3Y9NcvmwDQAAy9rUorm7P5zkH3fa/ZwkFw63L0zy3Gk9PwAA7C1Lvab58O6+cbj9xSSH39eBVXVWVV1ZVVdu27ZtaaYDAIDdmNkLAbu7k/Qe7r+guzd094ZDDz10CScDAIBvtNTRfFNVHZEkw9ebl/j5AQDgflvqaH5vktOH26cnuXiJnx8AAO63ab7l3NuT/FmS76qqG6rqjCTnJTmxqrYm+bfDNgAALGsrp3Xi7n7xfdz1jGk9JwAATINPBAQAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAAAYIZoBAGCEaAYAgBGiGQAARohmAKReXEgAAAT6SURBVAAYIZoBAGCEaAYAgBGiGQAARswkmqvq5Kr6dFV9pqrOncUMAACwWEsezVW1IslvJjklyTFJXlxVxyz1HAAAsFizuNJ8fJLPdPdnu/vrSd6R5DkzmAMAABaluntpn7DqtCQnd/crhu2XJXlyd//ETsedleSsYfO7knx6SQddvh6Z5EuzHoJlx+8Fu+P3gt3xe8HO/E78s+/s7kN3d8fKpZ5ksbr7giQXzHqO5aaqruzuDbOeg+XF7wW74/eC3fF7wc78TizOLJZnfD7JoxdsHzXsAwCAZWkW0fyJJI+tqqOr6iFJfjjJe2cwBwAALMqSL8/o7ruq6ieS/FGSFUl+t7u3LPUc+zBLVtgdvxfsjt8LdsfvBTvzO7EIS/5CQAAA2Nf4REAAABghmgEAYIRoBgCAEcv2fZpJqurxmXxa4pHDrs8neW93Xze7qYDlaPj34sgkH+vu2xfsP7m7L53dZMxSVR2fpLv7E1V1TJKTk3yqu98/49FYRqrq/3b3y2c9x3LnhYDLVFW9OsmLM/mY8RuG3Udl8hZ97+ju82Y1G8tXVf1od79p1nOwtKrqPyU5O8l1SeaSvLK7Lx7u+2R3HzfL+ZiNqnpNklMyuUB2WZInJ/lQkhOT/FF3//IMx2NGqmrnt/mtJE9P8sEk6e5nL/lQ+wjRvExV1d8kOba779xp/0OSbOnux85mMpazqvr77n7MrOdgaVXVXyV5anffXlVrkmxO8pbufkNVXd3dT5rpgMzE8Hsxl2RVki8mOaq7b6uqgzL5LxLfM9MBmYmq+mSSv07yO0k6k2h+eyYX5dLdfzy76ZY3yzOWr3uSPCrJ53baf8RwHweoqvrL+7oryeFLOQvLxoN2LMno7vmq+v4km6vqOzP5veDAdFd3353kq1X1t919W5J09/aq8r8jB64NSV6Z5L8m+ZnuvqaqtovlcaJ5+XpVksuramuS64d9j0myNslPzGwqloPDk/xgklt22l9J/nTpx2EZuKmq5rr7miQZrjifmuR3k3z3bEdjhr5eVd/S3V9Nsn7Hzqr6trj4csDq7nuS/HpVvXv4elP04KL4IS1T3X1pVT0uyfH5xhcCfmK4csCB631JDt4RSAtV1RVLPw7LwMuT3LVwR3ffleTlVfVbsxmJZeBp3f215N5Q2uHBSU6fzUgsF919Q5IfqqpnJrlt1vPsC6xpBgCAEd6nGQAARohmAAAYYU0zwDJXVd+e5PJh8zuS3J1k27B9fHd/fSaDARxArGkG2IdU1c8nub27f2XWswAcSCzPANgHVdUzqurqqvqrqvrdqlo17J+vqtcN+z9eVWvv4/G3V9UvV9VfVNWfV5X3+AbYA9EMsO95aJI3J3lRd393Jkvt/sOC+/9p2P8bSV5/H+d4WJI/7+4nJvlwkjOnNy7Avk80A+x7ViT5u+7+m2H7wiRPW3D/2xd8fep9nOPrmbznd5JclWTNXp4RYL8imgH2PwtfrNJVtaKqrhn+/OKw/87+5xe13B0vDAfYI/9IAux77k6ypqrWdvdnkrwsyR8vuP9FSc4bvv7Z8Cmic0s/JsD+QzQD7HvuSPKjSd5dVSuTfCLJ/1lw/8Or6i+TfC3Ji2cwH8B+x1vOAexHqmo+yYbu/tKsZwHYn1jTDAAAI1xpBgCAEa40AwDACNEMAAAjRDMAAIwQzQAAMEI0AwDACNEMAAAj/n8cmob+nuVk9AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we take into account multiple top predicted labels, the accuracy is noticeably increased from approx. 30% up to 65% (top-5)."
      ],
      "metadata": {
        "id": "C3SqmuSAZ9zQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPvaKD2c__Lc"
      },
      "source": [
        "# 4. Conclusion for zero-shot classification\n",
        "\n",
        "#### Basis for built-in topic classification of exam questions\n",
        "The huggingface pipeline is ideal for our use case: we want to add useful, predefined topic metadata to our exam questions. E.g. a user of the AssessmentQ platform creates a new exam question, we pass the question text to the zero-shot pipeline along with predefined topics (these topics are based on the sector of the client: Mathematics, Chemistry, ... for example). The pipeline then gives us the topic label(s) with the highest likelihood. User feedback would be possible, we give the user our prediction and the user indicates if the prediction is correct or not, if not the user gives us the correct label. This way we can build a correctly labeled dataset for further AI projects.\n",
        "\n",
        "#### Generate training data\n",
        "Another use case for the zero-shot pipeline is to directly use the zero-shot predictions to generate a labeled dataset. In this case we only take labels that are the most likely to be correct (with a high probability). E.g. let's take all label predictions with a probability above 85% and consider them to be true.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y2Cou2RzbbeZ"
      ],
      "name": "QM02_zero-shot-approach.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz9g2MZfnQzzIVw4CSCyeR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}